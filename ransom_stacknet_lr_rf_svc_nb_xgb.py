import pandas as pd
import collections
import re
from sklearn.model_selection import train_test_split
import lime
import sklearn
import numpy as np
import sklearn
import sklearn.ensemble
import sklearn.metrics
import sklearn.feature_extraction
from sklearn.naive_bayes import MultinomialNB
from lime import lime_text
from sklearn.pipeline import make_pipeline
from lime.lime_text import LimeTextExplainer
from sklearn.cross_validation import StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from mlxtend.classifier import EnsembleVoteClassifier
import xgboost as xgb

filename_data = "result/lime_data_stacknet_lr_rf_svc_nb_xgbt_24.txt"
filename_label = "result/lime_label_stacknet_lr_rf_svc_nb_xgb_24.txt"
criteria = "result/criteria_stacknet_lr_rf_svc_nb_xgb_24.txt"
f_1_f = "result/f_1_lr_rf_svc_nb_xgbt_24.txt"
api_stacknet = "result/api_stacknet_lr_rf_svc_nb_xgbt_24.txt"
file_result = "result/result_stacknet_lr_rf_svc_nb_xgbt_24.txt"
tweakler = 10 # samples to be fed

data = pd.read_csv("RansomwareData_2.csv")

good_data = data[581:660]

dataset_dictionary = {}

with open("ransom_api_list.txt", "r") as f:
    dataset = f.readlines()
    for i in dataset:
        d = re.sub("\n", "", i)
        d_1 = re.sub("API:", "", d)
        a, b = d_1.split(";")
        n = int(a) - 4
        if n == 0:
            s = str(n)
            dataset_dictionary[s] = str(b)
        else:
            s = "0." + str(n)
            dataset_dictionary[s] = str(b)

reg_dictionary = {}

with open("reg.txt", "r") as f:
    dataset = f.readlines()
    for i in dataset:
        a, d_0 = i.split(";")
        d = re.sub("\n", "", d_0)
        d_1 = re.sub("REG:", "", d)
        d_2 = re.sub(r"\\", r"slash", d_1)
        d_3 = re.sub(r"\/", r"revslash", d_2)
        d_4 = re.sub(" ", "", d_3)
        d_5 = re.sub(r"\{", "quotation1", d_4)
        d_6 = re.sub(r"\}", "quotation2", d_5)
        d_7 = re.sub(r"\-", "bar", d_6)
        d_8 = re.sub(r"\.", "point", d_7)
        d_9 = re.sub(r":", "doublecolon", d_8)
        d_10 = re.sub(r"=", "equal", d_9)
        d_11 = re.sub(r"&", "and", d_10)
        n = int(a) - 4
        if n == 0:
            s = str(n)
            reg_dictionary[s] = str(d_11)
        else:
            s = "0." + str(n)
            reg_dictionary[s] = str(d_11)
#print reg_dictionary
del reg_dictionary["0.5582"]
del reg_dictionary["0.4971"]
del reg_dictionary["0.2840"]
del reg_dictionary["0.2459"]
#print reg_dictionary

dataset_label = []
dataset_api = []
target_label = ["2", "5", "6", "9"] #check!
for index, row in data.iterrows():
    for i in target_label:
        if row["2"] == int(i):
            dataset_label.append(str(row["2"]))
            string_letter = []
            for k, v in dataset_dictionary.items():
                if row[k] == 1:
                    if re.compile("reg", re.IGNORECASE).search(v):
                        continue
                    elif re.compile("key", re.IGNORECASE).search(v):
                        list_of_avoid = ["RegQueryInfoKey", "NtEnumerateKey", "GetAsyncKeyState", "RegEnumKeyEx", "GetKeyState", "CryptExportKey", "CryptGenKey"]
                        for j in list_of_avoid:
                            if re.compile(j, re.IGNORECASE).search(v):
                                string_letter.append(v)
                            else:
                                continue
                    else:
                        string_letter.append(v) 
                else:
                    continue
        else:
            continue
        string_let = ",".join(string_letter)
        dataset_api.append(string_let)
    #count = 0
    #if row["2"] == 0:
       # if count > 90:
           # break
       # else:
           # dataset_label.append(row["2"])
           # string_letter = []
           # for k, v in dataset_dictionary.items():
               # if row[k] == 1:
                   # string_letter.append(v)
               # else:
                   # continue
           # for k, v in reg_dictionary.items():
               # if row[k] == 1:
                   # string_letter.append(v)
               # else:
                   # continue
             
       # count = count + 1

for index, row in good_data.iterrows():
    if row["2"] == 0:
        dataset_label.append(str(row["2"]))
        string_letter = []
        for k, v in dataset_dictionary.items():
            if row[k] == 1:
                if re.compile("reg", re.IGNORECASE).search(v):
                    continue
                elif re.compile("key", re.IGNORECASE).search(v):
                    list_of_avoid = ["RegQueryInfoKey", "NtEnumerateKey", "GetAsyncKeyState", "RegEnumKeyEx", "GetKeyState", "CryptExportKey", "CryptGenKey"]
                    for j in list_of_avoid:
                        if re.compile(j, re.IGNORECASE).search(v):
                            string_letter.append(v)
                        else:
                            continue
                else:
                    string_letter.append(v)
            else:
                continue
        s = ",".join(string_letter)
        dataset_api.append(s)
    else:
        continue

#print "dataset_label is " + str(len(dataset_label))
#print dataset_label
#print "dataset_api is " + str(len(dataset_api))
print dataset_api

class_names = ["0", "2", "5", "6", "9"] #check!

x_train, x_test, y_train, y_test = train_test_split(dataset_api, dataset_label, test_size=0.1)

vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False)

train_vectors = vectorizer.fit_transform(x_train)
test_vectors = vectorizer.transform(x_test)

clf1 = LogisticRegression(random_state=0)
clf2 = RandomForestClassifier(random_state=0)
clf3 = SVC(random_state=0, probability=True)
clf4 = MultinomialNB(alpha=.01)
clf5 = xgb.XGBClassifier()
eclif = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3, clf4, clf5],
                              weights=[2, 4, 2, 4, 7], voting='soft')
eclif.fit(train_vectors, y_train)

pred = eclif.predict(test_vectors)

f_1 = sklearn.metrics.f1_score(y_test, pred, average='weighted')
print "f_1 is " + str(f_1)

with open(f_1_f, "w") as f:
    f.write("f_1 is " + str(f_1))

c = make_pipeline(vectorizer, eclif)

nb_success = 0
nb_fail = 0

result_list = []
result_label = []
result_accepted_list_ml = []
result_accepted_list_lime = []

explainer = LimeTextExplainer(class_names=class_names)
for i in range(len(x_test)-tweakler):
    #print "i is " + x_test[i]
    if str(eclif.predict(test_vectors[i]).reshape(1,-1)[0,0]) == y_test[i]:
        nb_success = nb_success + 1
        exp = explainer.explain_instance(x_test[i], c.predict_proba, num_features=6)
        ans = exp.as_list()
        result_list.append(ans)
        res = str(eclif.predict(test_vectors[i]).reshape(1,-1)[0,0]) + "_" + str(y_test[i])
        result_label.append(res)
        result_accepted_list_ml.append(i)
    else:
        nb_fail = nb_fail + 1
        continue    

print "nb_success " + str(nb_success)
print "nb_fail" + str(nb_fail)

with open(filename_data, "w") as f_1, open(filename_label, "w") as f_2:
    for (i_1, i_2) in zip(result_list, result_label):
        l_api_dic = {}
        haha = i_2.split("_")
        if haha[0] == haha[1]:
            f_2.write(i_2 + "\n")
            d = []
            for j in i_1:
                j_1 = re.sub("\-", "", str(j[1]))
                l_api_dic[str(j[0])] = float(j_1)
            l_api_sum = []
            for k, v in l_api_dic.items():
                l_api_sum.append(v)
            s_u_m = sum(l_api_sum)
            for k, v in l_api_dic.items():
                l_api_dic[k] = l_api_dic[k]/s_u_m
            for k, v in l_api_dic.items():
                d.append(k + "dash" + str(v))
            s = ",".join(d)
            f_1.write(s + "\n")
        else:
            #print "Unmathed. Will be abort"
            continue
with open(filename_data, "r") as f_1, open(filename_label, "r") as f_2, open(criteria, "w") as f_3, open(file_result, "w+") as f_4:

    data = []
    label = []

    data_1 = f_1.readlines()
    for i in data_1:
        t = i.strip()
        data.append(t)
    label_1 = f_2.readlines()
    for i in label_1:
        t = i.strip()
        label.append(t)

    if len(data) == len(label):
        
        lab_0 = []
        lab_2 = []
        lab_5 = [] 
        lab_6 = []
        lab_9 = []

        for (i_1, i_2) in zip(data, label):
            if re.compile("0", re.IGNORECASE).search(i_2):
                lab_0.append(i_1)
            elif re.compile("2", re.IGNORECASE).search(i_2):
                lab_2.append(i_1)
            elif re.compile("5", re.IGNORECASE).search(i_2):
                lab_5.append(i_1)
            elif re.compile("6", re.IGNORECASE).search(i_2):
                lab_6.append(i_1)
            elif re.compile("9", re.IGNORECASE).search(i_2):
                lab_9.append(i_1)
            #check!
            else:
                print "sth wrong"

           

        def label_checker(list_of_l):
            #print list_of_l
            a = {}
            list_key = []
            list_val = []
            for j in list_of_l:
                dash = j.strip().split(",")
                for k in dash:
                    j_1, j_2 = k.split("dash")
                    list_key.append(j_1)
                    list_val.append(float(j_2))
            a_d = collections.Counter(list_key)
            a_d_1 = {k:v for k, v in a_d.iteritems()}
            for k, v in a_d_1.items():
                if v > 1:
                    list_a = []
                    list_an = [j for j, x in enumerate(list_key) if x == k]
                    for l in list_an: 
                        list_a.append(list_val[l])
                    arr = np.array(list_a)
                    avg = np.average(arr)
                    a[k] = avg
                else:
                    a[k] = list_val[list_key.index(k)]

            return a
        l_0 = label_checker(lab_0)
        l_2 = label_checker(lab_2)           
        l_5 = label_checker(lab_5)
        l_6 = label_checker(lab_6)
        l_9 = label_checker(lab_9)
        #check!

        def dictionary_standariser(list_of_l):
            sum_up = []
            for v in list_of_l.values():
                sum_up.append(v)
                
            s = sum(sum_up)
            for k in list_of_l.keys():
                list_of_l[k] = list_of_l[k]/s


        dictionary_standariser(l_0)
        dictionary_standariser(l_2)
        dictionary_standariser(l_5)
        dictionary_standariser(l_6)
        dictionary_standariser(l_9)
        #check!
        print "l_0"
        print l_0
        print "l_2"
        print l_2
        print "l_5"
        print l_5
        print "l_6"
        print l_6
        print "l_9"
        print l_9
        #check!
        def write_dic(l_x, string_lab):
            f_3.write("label " + string_lab + "\n")
            for k, v in l_x.items():
                f_3.write(str(k) + "_" + str(v) + "\n")

        write_dic(l_0, "0")
        write_dic(l_2, "2")
        write_dic(l_5, "5")
        write_dic(l_6, "6")
        write_dic(l_9, "9")
        # check!

        result = {"0":0, "2":0, "5":0, "6":0, "9":0} #check!

        success = 0
        fail = 0

        for i in range(len(x_test)-tweakler):
            data = x_test[i].split(",")
            #print data
            r_0 = 0
            r_2 = 0
            r_5 = 0
            r_6 = 0
            r_9 = 0
            #check!

            for k, v in l_0.items():
                n = data.count(k)
                n_v = n * v
                r_0 = r_0 +  n * v
            result["0"] = r_0
            for k, v in l_2.items():
                n = data.count(k)
                n_v = n * v
                result["2"] = n * v
                r_2 = r_2 +  n * v
            result["2"] = r_2
            for k, v in l_5.items():
                n = data.count(k)
                n_v = n * v
                result["5"] = n * v
                r_5 = r_5 +  n * v
            result["5"] = r_5
            for k, v in l_6.items():
                n = data.count(k)
                n_v = n * v
                result["6"] = n * v
                r_6 = r_6 +  n * v
            result["6"] = r_6
            for k, v in l_9.items():
                n = data.count(k)
                n_v = n * v
                result["9"] = n * v
                r_9 = r_9 +  n * v
            result["9"] = r_9
            #check!            
            r = []
            for k, v in sorted(result.items(), key=lambda x:-x[1]):
                r.append(k)
            answer = str(r[0])
            if answer == y_test[i]:
                success = success + 1
                result_accepted_list_lime.append(i)
            else:
                fail = fail + 1

        print "success is " + str(success)
        print "fail is " + str(fail)
        
        f_4.write("The success is " + str(success) + "\n")
        f_4.write("The fail is " + str(fail))
        f_4.write("The ML\n")
        for i in result_accepted_list_ml:
            f_4.write(str(i) + "\n")
        f_4.write("LIME\n")
        for i in result_accepted_list_lime:
            f_4.write(str(i) + "\n")
    else:
            print "its error"

